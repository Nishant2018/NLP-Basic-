{"cells":[{"metadata":{"_cell_guid":"98c5c304-c58c-4f97-947c-49a98a187af3","_uuid":"f4032b042154661728b4b2d7851a21530a66e621"},"cell_type":"markdown","source":"# Explaining the NLP terms   <br>\n<div class=\"section\" id=\"the-bag-of-words-representation\">\n<h3>1 The Bag of Words representation<a class=\"headerlink\" href=\"#the-bag-of-words-representation\" title=\"Permalink to this headline\">¶</a></h3>\n<p>Text Analysis is a major application field for machine learning\nalgorithms. However the raw data, a sequence of symbols cannot be fed\ndirectly to the algorithms themselves as most of them expect numerical\nfeature vectors with a fixed size rather than the raw text documents\nwith variable length.</p>\n<p>In order to address this, scikit-learn provides utilities for the most\ncommon ways to extract numerical features from text content, namely:</p>\n<ul class=\"simple\">\n<li><strong>tokenizing</strong> strings and giving an integer id for each possible token,\nfor instance by using white-spaces and punctuation as token separators.</li>\n<li><strong>counting</strong> the occurrences of tokens in each document.</li>\n<li><strong>normalizing</strong> and weighting with diminishing importance tokens that\noccur in the majority of samples / documents.</li>\n</ul>\n<p>In this scheme, features and samples are defined as follows:</p>\n<ul class=\"simple\">\n<li>each <strong>individual token occurrence frequency</strong> (normalized or not)\nis treated as a <strong>feature</strong>.</li>\n<li>the vector of all the token frequencies for a given <strong>document</strong> is\nconsidered a multivariate <strong>sample</strong>.</li>\n</ul>\n<p>A corpus of documents can thus be represented by a matrix with one row\nper document and one column per token (e.g. word) occurring in the corpus.</p>\n<p>We call <strong>vectorization</strong> the general process of turning a collection\nof text documents into numerical feature vectors. This specific strategy\n(tokenization, counting and normalization) is called the <strong>Bag of Words</strong>\nor “Bag of n-grams” representation. Documents are described by word\noccurrences while completely ignoring the relative position information\nof the words in the document.</p>\n</div>\n<p><a class=\"reference internal\" href=\"generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer\" title=\"sklearn.feature_extraction.text.CountVectorizer\"><code class=\"xref py py-class docutils literal\"><span class=\"pre\">CountVectorizer</span></code></a> implements both tokenization and occurrence\ncounting in a single class:</p>"},{"metadata":{"_cell_guid":"d19d5e90-a77a-48a4-b789-e78753e369cd","collapsed":true,"_uuid":"0eb16b0a1e4b74ccad01f47370bf16e6ba5d0baa","trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ba40f73f-7095-4df4-af77-a8bdc5294fe6","_uuid":"3263da18041071f7b324e3c9a88f1feae5720be0","trusted":true},"cell_type":"code","source":"vect = CountVectorizer()\nvect","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"27152481-d49f-4dcf-ba59-a1b666744279","_uuid":"99d1a5edc81162dd53e3cf404e613ae92d5a657d"},"cell_type":"markdown","source":"<br><p>Let’s use it to tokenize and count the word occurrences of a minimalistic\ncorpus of text documents:</p>"},{"metadata":{"_cell_guid":"b069d6f1-3a7d-4244-8554-b06a85d25489","_uuid":"9ee0592c12ef4bafbd886adc208ab2c07d6f1380","trusted":true},"cell_type":"code","source":"corpus = ['Hi my name is kanav.','I love reading.','Kanav loves reading scripts.']\nX= vect.fit_transform(corpus)\nX # note the dimensions of X(3X9) means 3 rows and 9 columns. ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"56b04008-af4a-4693-ac87-9082013513a6","_uuid":"9be3b64dbd7d47f7180b50567b42af6628589b8e"},"cell_type":"markdown","source":"<br>Note the dimensions of X (3X9) means 3 rows and 9 columns. <br>\nas there are three documents and 9 unique words<br>\nSee"},{"metadata":{"_cell_guid":"7c1a646b-a698-49ac-ba03-776daf18b68f","_uuid":"aa0e66b552c7f11339caa93baa36caf5084714e4","trusted":true},"cell_type":"code","source":"vect.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b95ed7a8-2f13-49b5-8ef0-94fbc6deb50d","_uuid":"44c97e6e6db143493d2542ad296f5cddba6e3b05"},"cell_type":"markdown","source":"### See this is the frequency matrix in the given documents"},{"metadata":{"_cell_guid":"5cbcfa14-baee-4a46-af66-011bc24c6a01","_uuid":"bab67cdd065aa5dc7b28da8cee62b823140d771d"},"cell_type":"markdown","source":"Each term found by the analyzer during the fit is assigned a unique integer index corresponding to a column in the resulting matrix. This interpretation of the columns can be retrieved as follows:"},{"metadata":{"_cell_guid":"c25ac4c3-2283-4822-b01c-98634f216e8e","_uuid":"5a3fa876b5b4770d411c5870e982d384fd763a62","trusted":true},"cell_type":"code","source":"X.toarray()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4be526e6-c7b7-45e0-9206-03916234fb68","_uuid":"faffe49878430e8b73ce2b58b70976d3a9410ddf"},"cell_type":"markdown","source":"Hence words that were not seen in the training corpus will be completely ignored in future calls to the transform method:"},{"metadata":{"_cell_guid":"022e678a-bd1a-45ce-abbc-6c1ff7c2d945","_uuid":"a229b172df59e679eedb8f91b4176cc8f7bbba94","trusted":true},"cell_type":"code","source":"vect.transform(['hi,whats your name?.']).toarray()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7606035a-e08d-42b3-adfe-690c3b72f248","_uuid":"ab3c29d7c170928c5f2bb2b6d7d7949358fd5cc6"},"cell_type":"markdown","source":"### Normalization and stemming\nSince the words like love and loves has same meaning so, why not we treat them same?\n"},{"metadata":{"_cell_guid":"cf31de02-63be-459c-b23a-dd316c1e5fa8","_uuid":"4acdb60ec8ab8761e1a2f2f9879f1b0c8c003533","trusted":true},"cell_type":"code","source":"import nltk\nporter = nltk.PorterStemmer()\n[porter.stem(t) for t in vect.get_feature_names()]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"95f4f41d-4f0d-4ddc-a013-50f17a825550","_uuid":"c5cfdc86f340649b0f1515c43fe41445e0a53ea5"},"cell_type":"markdown","source":"See the loves has now become love."},{"metadata":{"_cell_guid":"bb7df4d3-389f-4f38-b64a-010eac28da36","_uuid":"b130e487e31662ad3bbda2957c5b771015a5f854"},"cell_type":"markdown","source":"Now we have total 8 unique features"},{"metadata":{"_cell_guid":"331447f9-bf8a-4565-9dd0-3ca290eb80ee","_uuid":"59ec85c98e287e17031689b12155a736097f549c","trusted":true},"cell_type":"code","source":"list(set([porter.stem(t) for t in vect.get_feature_names()]))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"46c00b36-7a39-4836-87c1-c6c12e0d4112","_uuid":"cf1dbd710652ff529bfc380667bf3fdcd371bea3","trusted":true},"cell_type":"code","source":"WNlemma = nltk.WordNetLemmatizer()\n[WNlemma.lemmatize(t) for t in list(set([porter.stem(t) for t in vect.get_feature_names()]))]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a8102f0f-ce68-4584-a578-3a9f24a47678","_uuid":"0dcfd364a150043cd6890471fc40cd6c99573949"},"cell_type":"markdown","source":"# Lemmatization\nA very similar operation to stemming is called lemmatizing. The major difference between these is, as you saw earlier, stemming can often create non-existent words, whereas lemmas are actual words.\n\nSo, your root stem, meaning the word you end up with, is not something you can just look up in a dictionary, but you can look up a lemma.\n\nSome times you will wind up with a very similar word, but sometimes, you will wind up with a completely different word. Let's see some examples."},{"metadata":{"_cell_guid":"ecad571a-f85c-4db4-a115-f2f35c31c45d","_uuid":"9622010ce3f85837073aa66d39ffd9c59bf682b6","trusted":true,"scrolled":true},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\n\nlemmatizer = WordNetLemmatizer()\nprint(lemmatizer.lemmatize(\"cats\"))\nprint(lemmatizer.lemmatize(\"cacti\"))\nprint(lemmatizer.lemmatize(\"geese\"))\nprint(lemmatizer.lemmatize(\"rocks\"))\nprint(lemmatizer.lemmatize(\"python\"))\nprint(lemmatizer.lemmatize(\"better\", pos=\"a\"))\nprint(lemmatizer.lemmatize(\"best\", pos=\"a\"))\nprint(lemmatizer.lemmatize(\"run\"))\nprint(lemmatizer.lemmatize(\"run\",'v'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b36c6c6dc68256f8fe6689e745f2c9ef656ed9d"},"cell_type":"markdown","source":"**Part of speech tagging** :Apart from the grammar relations, every word in a sentence is also associated with a part of speech (pos) tag (nouns, verbs, adjectives, adverbs etc). The pos tags defines the usage and function of a word in the sentence. H ere is a list of all possible pos-tags defined by Pennsylvania university. Following code using NLTK performs pos tagging annotation on input text. (it provides several implementations, the default one is perceptron tagger)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a9e8b48a33d6abcbb17f9735982790236e1c34fb"},"cell_type":"code","source":"from nltk import word_tokenize, pos_tag\nsentence = \"Kaggle is very good learning platform,Do you agree?\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a14c7d2110d89f542874063c393e9db1f736be73"},"cell_type":"code","source":"sen_token = word_tokenize(sentence)\npos_tag(sen_token)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2f8517763ca70425fb005398a25022416a5388a"},"cell_type":"markdown","source":"As you can see there the words are tagged by various parts of speech\n"},{"metadata":{"_uuid":"bc97285fb5c797d0041a31862eca506bf475c9de"},"cell_type":"markdown","source":"* ![](https://cdn-images-1.medium.com/max/800/0*V635bzjWK2n1jBsd.png)"},{"metadata":{"_cell_guid":"5c88128e-e6ed-405f-99b8-6dc253c09b32","collapsed":true,"_uuid":"243269f3e4cc6fdf02f2995b682aba74e1eb7ba3"},"cell_type":"markdown","source":"## Please upvote!\ni will be keep on updating !"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0326e14b73028d425c8836977890f49064837b2e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e0e5c7f5e71d70c81d41251c499e7b18c03accfc"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}